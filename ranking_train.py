# -*- coding: utf-8 -*-
"""SciBERT demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUoQiRKgwlTfZv44ZT8vrJqtSY9B2sXE
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install --quiet scann==1.2.8

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf 
from tensorflow import keras
from tensorflow.keras import Model,layers,Input
from tensorflow.keras.layers import *
from HelperFunctions import time_conv,time_sorter,time_splitter,last_n_taker,unique_definer,corpus_creator,sequencer_multi,sequencer_unique,input_label_maker
from HelperFunctions import train_neg_maker,release_year
from HelperFunctions_ranking import genre_splitter,date_extractor, sequencer,train_test_maker,train_neg_maker,test_negative_maker
from metrics import mapk
from models import ret_model,ranking_model
import os 
from sklearn.utils import shuffle
import pickle
import scann

import re
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn import preprocessing

movie_url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml_1M/movies.dat'
movies_df = pd.read_csv(movie_url, delimiter = '::',encoding='ISO-8859-1',header = None)
movies_df.columns = ['movie_id','movie_title','genres']

ratings_url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml_1M/ratings.dat'
ratings_df = pd.read_csv(ratings_url, delimiter = '::', header = None)
ratings_df.columns = ['user_id','movie_id','ratings','timestamp']

user_url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml_1M/users.dat'
users_df = pd.read_csv(user_url, delimiter = '::', header = None)
users_df.columns = ['user_id','gender', 'age', 'occupation', 'zip_code']

EMBEDDING_DIM = 256
SEQUENCE_LEN = 20
BATCH_SIZE = 512
NUM_EPOCHS = 100
NUM_EPOCHS_RANKING = 5
K = 40

def pickle_dumper(dictin,dictin_name):
    name_str = dictin_name+'.pkl'
    a_file = open(name_str, "wb")
    pickle.dump(dictin, a_file)
    a_file.close()

saving_path = 'drive/MyDrive/Colab Notebooks/two_stage_rec_2/'
# test_df.to_csv(saving_path+'test_df_retrieval.csv')
ranking_df = pd.read_csv('drive/MyDrive/Colab Notebooks/two_stage_rec_2/ranking_df.csv')

unique_movies_rank, num_unique_movies_rank = unique_definer(ranking_df,'item_id')
movie_2enc_rank, enc_2movie_rank = corpus_creator(unique_movies_rank, start_index = 0)

ranking_df = ranking_df.drop_duplicates()
ranking_df = ranking_df.drop(columns = ['movie_id'])
ranking_df['item_id_enc'] = ranking_df['item_id'].map(enc_2movie_rank)

ranking_df.head(3)
#### bu kisimda movie_id_enc_dusurulebilir

sequenced_df = sequencer_multi(ranking_df,'user_id')
sequenced_df = sequenced_df.drop(columns = ['movie_title','genres'])

users, negatives = train_neg_maker(4, sequenced_df,'item_id_enc',movie_2enc_rank)
negative_df_rank = pd.DataFrame({'user_id':np.add(users,1),'item_id_enc':np.concatenate(np.concatenate(negatives))})
negative_df_rank['ratings'] = np.zeros(len(negative_df_rank), dtype = 'int32')
negative_df_rank = negative_df_rank.reset_index(drop=True)

negative_df_rank['item_id'] = negative_df_rank['item_id_enc'].map(movie_2enc_rank)
negative_df_rank.head(3)

negative_df_rank = negative_df_rank.merge(movies_df, left_on='item_id', right_on= 'movie_id')
negative_df_rank = negative_df_rank.drop(columns = ['movie_id'])

ranking_df['ratings'] = np.ones(len(ranking_df), dtype = 'int32')
ranking_df = ranking_df.drop(columns = ['movie_id_enc']).reset_index(drop = True)

ranking_df = pd.concat([negative_df_rank,ranking_df])

ranking_df_test = ranking_df.copy()
ranking_df_test_diluted = ranking_df_test.drop(columns = ['user_id','ratings'])

ranking_df_test_diluted = ranking_df_test_diluted.drop_duplicates()

genres,total_genre = genre_splitter(ranking_df['genres'])
unique_genres = np.unique(np.concatenate(genres),return_counts =True)[0]

mlb = MultiLabelBinarizer()
mlb_fits = mlb.fit_transform(genres)
mlb.classes_

release_date = date_extractor(ranking_df['movie_title'])
np.unique(release_date,return_counts = True)

genre_enc = [np.array(i) for i in mlb_fits]
ranking_df['genre_enc'] = genre_enc
ranking_df['genre_count'] = total_genre
ranking_df['release_date'] = release_date
ranking_df['release_date_norm'] = preprocessing.normalize([ranking_df['release_date']])[0]

ranking_df =  ranking_df.reset_index(drop =True)
ranking_df = shuffle(ranking_df)
ranking_df.head(3)

unique_items_rank = ranking_df['item_id'].unique()
enc_2item_r = {i:j for i,j in enumerate(unique_items_rank)}
item_2enc_r = {j:i for i,j in enumerate(unique_items_rank)}

ranking_df['item_id_enc_rank'] = ranking_df['item_id'].map(item_2enc_r)
ranking_df.head(3)

genre_size = 18

tf.keras.utils.pad_sequences(
    ranking_df['genre_enc'],
    maxlen=18,
    dtype='int32',
    padding='pre',
    truncating='pre',
    value=0.0
)

input_user_id_rank = [np.array(i)  for i in (ranking_df['user_id'])]
input_movie_rank = [np.array(i)  for i in (ranking_df['item_id_enc_rank'])]
input_release_year_rank = [np.array(i, dtype = 'int32')  for i in (ranking_df['release_date'])]
input_genre_rank = [list(i) for i in (ranking_df['genre_enc'])]
input_genre_count_rank = [np.array(i)  for i in (ranking_df['genre_count'])]
input_release_date_norm_rank = [np.array(i)  for i in (ranking_df['release_date_norm'])]

deneme_df = pd.DataFrame({
    'input_user_id_rank' : input_user_id_rank,
    'input_movie_rank' : input_movie_rank,
    'input_release_year_rank' : input_release_year_rank,
    'input_genre_rank' : input_genre_rank,
    'input_genre_count_rank' : input_genre_count_rank,
    'input_release_date_norm_rank' : input_release_date_norm_rank
})

deneme_df

# genre_size = len(input_genre_rank[0])
# genre_size

unique_items_rank_len = 3366

# def ranking_model(unique_items_rank,EMBEDDING_DIM):
# def ranking_model(unique_items_rank,EMBEDDING_DIM,genre_size):
#     user_id_inp_rank =  Input(shape =(1,), name='user_id_input_rank')
#     movie_inp_rank = Input(shape =(1,), name='movie_input_rank')
#     release_year_inp_rank = Input(shape =(1,), name='release_year_input_rank')
#     genre_input = Input(shape = (genre_size,), name = 'genre_input')
#     genre_count_input = Input(shape = (1,), name = 'genre_count')
#     release_date_norm = Input(shape = (1,), name = 'release_date_norm')

#     emb_layer = Embedding(len(unique_items_rank), EMBEDDING_DIM)(movie_inp_rank)
#     flat_layer = Flatten(name = 'flatten_layer')(emb_layer) 
#     concat_layer = tf.keras.layers.Concatenate(axis=1)([flat_layer,user_id_inp_rank,release_year_inp_rank,genre_input,genre_count_input,release_date_norm])

#     d1 = Dense(256*4, activation = 'relu' , name = 'd1_layer')(concat_layer)    
#     d2 = Dense(256*2, activation = 'relu', name = 'd2_layer')(d1)
#     d3 = Dense(256*1, activation = 'relu', name = 'd3_layer')(d2)
#     final = Dense(1, activation = 'sigmoid', name = 'sigmoid_layer')(d3)
#     return Model(inputs = [user_id_inp_rank,movie_inp_rank,release_year_inp_rank,genre_input,genre_count_input,release_date_norm], outputs = final)

ranking_model = ranking_model(unique_items_rank,EMBEDDING_DIM,genre_size)

ranking_model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = 'Adam',
    metrics = ['accuracy'],
)

ranking_model.fit(
    [tf.constant(input_user_id_rank),
     tf.constant(input_movie_rank),
     tf.constant(input_release_year_rank),
     tf.constant(input_genre_rank),
     tf.constant(input_genre_count_rank),
     tf.constant(input_release_date_norm_rank)
     ],
     tf.constant(ranking_df['ratings']),
     epochs = NUM_EPOCHS_RANKING,
     batch_size = 256
)
rank_model_name = 'ranking_model_weights.h5'

ranking_model.save_weights(saving_path +str(NUM_EPOCHS_RANKING)+'epochs_'+rank_model_name)
# ranking_model.load_weights(saving_path +str(NUM_EPOCHS_RANKING)+'epochs_'+rank_model_name)

# num = 110
# ranking_model.predict(
#     [tf.constant(input_user_id_rank)[num:num+2],
#      tf.constant(input_movie_rank)[num:num+2],
#      tf.constant(input_release_year_rank)[num:num+2],
#      tf.constant(input_genre_rank)[num:num+2],
#      tf.constant(input_genre_count_rank)[num:num+2],
#      tf.constant(input_release_date_norm_rank)[num:num+2]
#      ])

